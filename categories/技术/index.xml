<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on 困惑的人生</title>
    <link>https://palagend.github.io/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 困惑的人生</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Thu, 19 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://palagend.github.io/categories/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux /sys目录下各个子目录说明</title>
      <link>https://palagend.github.io/posts/2019/09/linux-/sys%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%90%84%E4%B8%AA%E5%AD%90%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E/</link>
      <pubDate>Thu, 19 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://palagend.github.io/posts/2019/09/linux-/sys%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%90%84%E4%B8%AA%E5%AD%90%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E/</guid>
      <description>/sys/devices  该目录下是全局设备结构体系，包含所有被发现的注册在各种总线上的各种物理设备。一般来说，所有的物理设备都按其在总线上的拓扑结构来显示，但有两个例外，即platform devices和system devices。platform devices一般是挂在芯片内部的高速或者低速总线上的各种控制器和外设，它们能被CPU直接寻址；system devices不是外设，而是芯片内部的核心结构，比如CPU，timer等，它们一般没有相关的驱动，但是会有一些体系结构相关的代码来配置它们。
(sys/devices是内核对系统中所有设备的分层次表达模型，也是/sys文件系统管理设备的最重要的目录结构)
 /sys/dev  该目录下维护一个按照字符设备和块设备的主次号码(major:minor)链接到真是设备(/sys/devices)的符号链接文件。
 /sys/class  该目录下包含所有注册在kernel里面的设备类型，这是按照设备功能分类的设备模型，每个设备类型表达具有一种功能的设备。每个设备类型子目录下都是这种设备类型的各种具体设备的符号链接，这些链接指向/sys/devices/name下的具体设备。设备类型和设备并没有一一对应的关系，一个物理设备可能具备多种设备类型；一个设备类型只表达具有一种功能的设备，比如：系统所有输入设备都会出现在/sys/class/input之下，而不论它们是以何种总线连接到系统的。(/sys/class也是构成linux统一设备模型的一部分)
 /sys/block  该目录下的所有子目录代表着系统中当前被发现的所有块设备。按照功能来说放置在/sys/class下会更合适，但由于历史遗留因素而一直存在于/sys/block，但从linux 2.6.22内核开始这部分就已经标记为过去时，只有打开了CONFIG_SYSFS_DEPRECATED配置编译才会有这个目录存在，并且其中的内容在从linux2.6.26版本开始已经正式移到了/sys/class/block，旧的接口/sys/block为了向后兼容而保留存在，但其中的内容已经变为了指向它们在/sys/devices/中真实设备的符号链接文件。
 /sys/bus  该目录下的每个子目录都是kernel支持并且已经注册了的总线类型。这是内核设备按照总线类型分层放置的目录结构，/sys/devices中的所有设备都是连接于某种总线之下的，bus子目录下的每种具体总线之下可以找到每个具体设备的符号链接，一般来说每个子目录(总线类型)下包含两个子目录，一个是devices，另一个是drivers；其中devices下是这个总线类型下的所有设备，这些设备都是符号链接，它们分别指向真正的设备(/sys/devices/name/下)；而drivers下是所有注册在这个总线上的驱动，每个driver子目录下 是一些可以观察和修改的driver参数。 (它也是构成linux统一设备模型的一部分)
 /sys/fs  按照设计，该目录用来描述系统中所有的文件系统，包括文件系统本身和按照文件系统分类存放的已挂载点。
 /sys/kernel  这个目录下存放的是内核中所有可调整的参数
 /sys/firmware  这里是系统加载固件机制的对用户空间的接口，关于固件有专用于固件加载的一套API，在附录 LDD3 一书中有关于内核支持固件加载机制的更详细的介绍；
 /sys/module  该目录下有系统中所有的模块信息，不论这些模块是以内联(inlined)方式编译到内核映像文件中还是编译为外模块(.ko文件)，都可能出现在/sys/module中。即module目录下包含了所有的被载入kernel的模块。
 /sys/power  该目录是系统中的电源选项，对正在使用的power子系统的描述。这个目录下有几个属性文件可以用于控制整个机器的电源状态，如可以向其中写入控制命令让机器关机/重启等等。</description>
    </item>
    
    <item>
      <title>Openstack Instance Ha Propersal</title>
      <link>https://palagend.github.io/posts/2019/07/openstack-instance-ha-propersal/</link>
      <pubDate>Thu, 11 Jul 2019 17:12:47 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2019/07/openstack-instance-ha-propersal/</guid>
      <description>This post is a copy from russellbryant
 In a perfect world, every workload that runs on OpenStack would be a cloud native application that is horizontally scalable and fault tolerant to anything that may cause a VM to go down. However, the reality is quite different. We continue to see a high demand for support of traditional workloads running on top of OpenStack and the HA expectations that come with them.</description>
    </item>
    
    <item>
      <title>Libvirt Xml</title>
      <link>https://palagend.github.io/posts/2019/06/libvirt-xml/</link>
      <pubDate>Sat, 29 Jun 2019 18:10:08 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2019/06/libvirt-xml/</guid>
      <description>#虚拟化类型为kvm(type=&#39;kvm&#39;)，可选的还有qemu &amp;lt;domain type=&#39;kvm&#39; xmlns:qemu=&#39;http://libvirt.org/schemas/domain/qemu/1.0&#39;&amp;gt; #虚拟机名字 openstack1-1 &amp;lt;name&amp;gt;openstack1-1&amp;lt;/name&amp;gt; #虚拟机预分配内存8388608K,这个是宿主机允许虚拟机使用的最大内存，并不是在虚拟机里用free看到的内存 &amp;lt;memory unit=&#39;KiB&#39;&amp;gt;8388608&amp;lt;/memory&amp;gt; #虚拟机当前定义内存(8388608)，free看到的内存，可以使用virsh setmem调整内存 &amp;lt;currentMemory unit=&#39;KiB&#39;&amp;gt;8388608&amp;lt;/currentMemory&amp;gt; #虚拟机cpu个数 &amp;lt;vcpu placement=&#39;static&#39;&amp;gt;4&amp;lt;/vcpu&amp;gt; &amp;lt;os&amp;gt; #模拟的系统架构x86_64,模拟机器类型rhel6.5 &amp;lt;type arch=&#39;x86_64&#39; machine=&#39;rhel6.5.0&#39;&amp;gt;hvm&amp;lt;/type&amp;gt; #虚拟机开机引导项，hd：硬盘，cdrom：光盘，即先硬盘，后光盘 &amp;lt;boot dev=&#39;hd&#39;/&amp;gt; &amp;lt;boot dev=&#39;cdrom&#39;/&amp;gt; &amp;lt;bootmenu enable=&#39;yes&#39;/&amp;gt; &amp;lt;bios useserial=&#39;yes&#39; rebootTimeout=&#39;0&#39;/&amp;gt; &amp;lt;/os&amp;gt; &amp;lt;features&amp;gt; &amp;lt;acpi/&amp;gt; &amp;lt;apic/&amp;gt; &amp;lt;pae/&amp;gt; &amp;lt;/features&amp;gt; #虚拟机cpu模拟类型，host-model，使用宿主机cpu的所有可使用特性 &amp;lt;cpu mode=&#39;host-model&#39;&amp;gt; &amp;lt;model fallback=&#39;allow&#39;/&amp;gt; &amp;lt;/cpu&amp;gt; &amp;lt;clock offset=&#39;utc&#39;/&amp;gt; &amp;lt;on_poweroff&amp;gt;destroy&amp;lt;/on_poweroff&amp;gt; &amp;lt;on_reboot&amp;gt;restart&amp;lt;/on_reboot&amp;gt; &amp;lt;on_crash&amp;gt;restart&amp;lt;/on_crash&amp;gt; &amp;lt;devices&amp;gt; #运行虚拟机的程序，qemu-kvm，可以在宿主机使用ps -ef | grep qemu-kvm 看到 &amp;lt;emulator&amp;gt;/usr/libexec/qemu-kvm&amp;lt;/emulator&amp;gt; #定义虚拟机磁盘 &amp;lt;disk type=&#39;file&#39; device=&#39;disk&#39;&amp;gt; #虚拟机磁盘为qcow2格式，如果你创建或使用的磁盘是raw格式，需要修改为raw &amp;lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39; cache=&#39;none&#39;/&amp;gt; #磁盘路径 &amp;lt;source file=&#39;/data/vhosts/jython/openstack/openstack1-1.disk&#39;/&amp;gt; #第一块为vda，第二块就为vdb，不能重复，重复虚拟机启动报错 &amp;lt;target dev=&#39;vda&#39; bus=&#39;virtio&#39;/&amp;gt; &amp;lt;/disk&amp;gt; &amp;lt;controller type=&#39;ide&#39; index=&#39;0&#39;&amp;gt; &amp;lt;/controller&amp;gt; &amp;lt;controller type=&#39;virtio-serial&#39; index=&#39;0&#39;&amp;gt; &amp;lt;/controller&amp;gt; &amp;lt;controller type=&#39;usb&#39; index=&#39;0&#39;&amp;gt; &amp;lt;/controller&amp;gt; #虚拟机网络为桥接模式bridge，桥接网桥为br-ex，要确保网桥br-ex存在，并且能使用 &amp;lt;interface type=&#39;bridge&#39;&amp;gt; &amp;lt;source bridge=&#39;br-ex&#39;/&amp;gt; &amp;lt;model type=&#39;virtio&#39;/&amp;gt; &amp;lt;/interface&amp;gt; #第二张网卡，如果需要多块网卡，就复制多次 &amp;lt;interface type=&#39;bridge&#39;&amp;gt; &amp;lt;source bridge=&#39;br-ex&#39;/&amp;gt; &amp;lt;model type=&#39;virtio&#39;/&amp;gt; &amp;lt;/interface&amp;gt; &amp;lt;console type=&#39;pty&#39;&amp;gt; &amp;lt;/console&amp;gt; &amp;lt;input type=&#39;mouse&#39; bus=&#39;ps2&#39;/&amp;gt; #使用vnc协议，autoport=&#39;yes&#39;:自动分配端口，从5900开始 &amp;lt;graphics type=&#39;vnc&#39; autoport=&#39;yes&#39; listen=&#39;0.</description>
    </item>
    
    <item>
      <title>Ceph Arch</title>
      <link>https://palagend.github.io/posts/2019/06/ceph-arch/</link>
      <pubDate>Fri, 28 Jun 2019 11:24:03 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2019/06/ceph-arch/</guid>
      <description>Ceph生态系统架构可以划分为四部分：
*client*：客户端（数据用户）。client向外export出一个POSIX文件系统接口，供应用程序调用，并连接mon/mds/osd，进行元数据及数据交互；最原始的client使用FUSE来实现的，现在写到内核里面了，需要编译一个ceph.ko内核模块才能使用。
*mon*：集群监视器，其对应的daemon程序为cmon（Ceph Monitor）。mon监视和管理整个集群，对客户端export出一个网络文件系统，客户端可以通过mount -t ceph monitor_ip:/ mount_point命令来挂载Ceph文件系统。根据官方的说法，3个mon可以保证集群的可靠性。
*mds*：元数据服务器，其对应的daemon程序为cmds（Ceph Metadata Server）。Ceph里可以有多个MDS组成分布式元数据服务器集群，就会涉及到Ceph中动态目录分割来进行负载均衡。
*osd*：对象存储集群，其对应的daemon程序为cosd（Ceph Object StorageDevice）。osd将本地文件系统封装一层，对外提供对象存储的接口，将数据和元数据作为对象存储。这里本地的文件系统可以是ext2/3，但Ceph认为这些文件系统并不能适应osd特殊的访问模式，它们之前自己实现了ebofs，而现在Ceph转用btrfs。</description>
    </item>
    
    <item>
      <title>在Windows10上利用minikube&#43;hyperv安装单节点k8s集群</title>
      <link>https://palagend.github.io/posts/2018/12/%E5%9C%A8windows10%E4%B8%8A%E5%88%A9%E7%94%A8minikube-hyperv%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9k8s%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Thu, 20 Dec 2018 00:55:02 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2018/12/%E5%9C%A8windows10%E4%B8%8A%E5%88%A9%E7%94%A8minikube-hyperv%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9k8s%E9%9B%86%E7%BE%A4/</guid>
      <description>准备好二进制文件 注意本教程使用的版本如下:
* minikube v0.31.0
* kubeadm v1.13.1
* kubelet v1.13.1
* kubectl v1.13.1
下载minikube, 下载命令:
curl -C - -L# -o $HOME/.local/bin/minikube https://github.com/kubernetes/minikube/releases/download/v0.31.0/minikube-windows-amd64  或者从这里下载源码编译
借助VPN下载二进制文件: kubeadm, kubelet, kubectl, 下载命令:
#VERSION=$(curl https://storage.googleapis.com/kubernetes-release/release/stable.txt) mkdir -p $HOME/.minikube/cache/v1.13.1 &amp;amp;&amp;amp; \ cd $HOME/.minikube/cache/v1.13.1 &amp;amp;&amp;amp; \ curl -C - -L#O https://storage.googleapis.com/kubernetes-release/release/v1.13.1/bin/windows/amd64/{kubelet,kubeadm,kubectl}  下载kubernetes所需的docker镜像, 脚本内容如下:
cat download-kubernetes.sh
#!/bin/bash #本脚本将拉取以下9个images #kube-proxy-amd64:v1.13.1 #kube-controller-manager-amd64:v1.13.1 #kube-scheduler-amd64:v1.13.1 #kube-apiserver-amd64:v1.13.1 #pause-amd64:3.1 #coredns:1.2.6 #etcd-amd64:3.2.24 #kubernetes-dashboard-amd64:v1.10.0 #flannel:v0.10.0-amd64 set -e #运行kubeadm config images list确认指定版本 K8S_VERSION=v1.13.1 ETCD_VERSION=3.</description>
    </item>
    
    <item>
      <title>Go语言源码分析</title>
      <link>https://palagend.github.io/posts/2018/12/go%E8%AF%AD%E8%A8%80%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 18 Dec 2018 20:09:44 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2018/12/go%E8%AF%AD%E8%A8%80%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>net/http client.go 结构: Client
变量: DefaultClient
接口: RoundTripper
函数: //TODO
Client指的是http客户端. 它的默认值是DefaultClient. 其中, DefaultClient以DefaultTransport作为传输层的.
典型的客户端传输层, 其内部具有缓存的TCP连接, 所以客户端应该优先重用, 而不是重新创建. 使用goroutines可以实现安全的客户端并发请求.
Client是比RoundTripper(Transport只是RounderTripper的一个实现)更高一级的存在, 用来处理重定向、cookie等HTTP细节.
 • when forwarding sensitive headers like &amp;ldquo;Authorization&amp;rdquo;, &amp;ldquo;WWW-Authenticate&amp;rdquo;, and &amp;ldquo;Cookie&amp;rdquo; to untrusted targets. These headers will be ignored when following a redirect to a domain that is not a subdomain match or exact match of the initial domain. For example, a redirect from &amp;ldquo;foo.com&amp;rdquo; to either &amp;ldquo;foo.com&amp;rdquo; or &amp;ldquo;sub.</description>
    </item>
    
    <item>
      <title>k8s知识点</title>
      <link>https://palagend.github.io/posts/2018/12/k8s%E7%9F%A5%E8%AF%86%E7%82%B9/</link>
      <pubDate>Tue, 18 Dec 2018 20:09:44 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2018/12/k8s%E7%9F%A5%E8%AF%86%E7%82%B9/</guid>
      <description> kube-proxy的两种转发模式（user space, kernel space） k8s后端服务的四种访问方式（ClusterIP, NodePort, LoadBalance, Ingress） k8s服务的三种端口(port, nodePort, targetPort)  </description>
    </item>
    
    <item>
      <title>使用minikube在linux上安装单节点k8s集群</title>
      <link>https://palagend.github.io/posts/2018/12/%E4%BD%BF%E7%94%A8minikube%E5%9C%A8linux%E4%B8%8A%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9k8s%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 18 Dec 2018 20:09:44 +0800</pubDate>
      
      <guid>https://palagend.github.io/posts/2018/12/%E4%BD%BF%E7%94%A8minikube%E5%9C%A8linux%E4%B8%8A%E5%AE%89%E8%A3%85%E5%8D%95%E8%8A%82%E7%82%B9k8s%E9%9B%86%E7%BE%A4/</guid>
      <description>准备好二进制文件 注意本教程使用的版本如下:
* minikube v0.31.0
* kubeadm v1.13.1
* kubelet v1.13.1
* kubectl v1.13.1
下载minikube, 下载命令:
mkdir -p $HOME/.minikube/cache/iso &amp;amp;&amp;amp; \ curl -C - -L# -o $HOME/.local/bin/minikube https://github.com/kubernetes/minikube/releases/download/v0.31.0/minikube-linux-amd64  或者从这里下载源码编译
借助VPN下载二进制文件: kubeadm, kubelet, kubectl, 下载命令:
#VERSION=$(curl https://storage.googleapis.com/kubernetes-release/release/stable.txt) mkdir -p $HOME/.minikube/cache/v1.13.1 &amp;amp;&amp;amp; \ cd $HOME/.minikube/cache/v1.13.1 &amp;amp;&amp;amp; \ sudo -E curl -C - -L#O https://storage.googleapis.com/kubernetes-release/release/v1.13.1/bin/linux/amd64/{kubelet,kubeadm,kubectl}  下载kubernetes所需的docker镜像, 脚本内容如下:
cat download-kubernetes.sh
#!/bin/bash #本脚本将拉取以下9个images #kube-proxy-amd64:v1.13.1 #kube-controller-manager-amd64:v1.13.1 #kube-scheduler-amd64:v1.13.1 #kube-apiserver-amd64:v1.13.1 #pause-amd64:3.1 #coredns:1.2.6 #etcd-amd64:3.2.24 #kubernetes-dashboard-amd64:v1.10.0 #flannel:v0.10.0-amd64 set -e #运行kubeadm config images list确认指定版本 K8S_VERSION=v1.</description>
    </item>
    
  </channel>
</rss>